# PostgreSQL Project
This project was another one from the Data Analytics bootcamp from Ironhack company. The PostgreSQL project summed up the third week of the course covering the topics about SQL.
This work was guided by a dataset about a bank which needs to separate its clients between good and bad ones to offer some services. The Berka dataset has many tables with important
information about the clients such as loans, creditcards, accounts and others. So my task was to find patterns with the data to set good and bad clients.
# Understanding the project
I started off my project by reading the documentation of the dataset to understand better what i should do to get into my results properly. I found some interesting points that
helped me to go through the work like the relation between the clients and the accounts because one of them could have many accounts and one account could be managed by many clients.
Also, i discovered that i could separate good and bad clients by looking to the table "loan" because it had the column "status" which had information about the loans paid by the 
customers. The status was featured by the contracts between the bank and the clients , if the client was ok with the payment he would be "C" and if he had finished the
contract paying all the loan he would be "A". Otherwise , he would be categorized into "B" or "D". So i decided to use the table "loan" as my base to understand what i should do.
# Analysing the relations.
After doing some research about the project to know if my reviews were 100% correctly, i used some functions in the Query tool to analyse the dataset. The function "SELECT" was the 
special one of course because it was the main function to do any of my work. I used this function to analyse all the dataset and to find common columns between the tables to implement
the "JOIN" function. I could analyse the data of many tables at the same time with this method because it uses a column that appears in both tables. So , i could merge the tables that
i would like to analyse. I started it with the tables "account" and "loan" because they both had the column "account_id" so i would have information about the client's accounts
 and this could give me interesting information related to the "status" mentioned above. This guided me to do the "INNER JOIN" function to merge these tables and work with their
 columns. The "JOIN" function was also great to eliminate null values at the dataset because many rows did not have the "status" quoted so i dropped it to have solid results.
 # Results.
 I decided to analyse the columns "payments", "amount" and "date" because i found interesting to achieve some good results to separate the clients. I started looking to the difference between the date of loan and the date of the account's creation to see if i could find any pattern related to the status. Calculating the average of the gap days between these two events for each status was the first thing i did. I concluded that the clients who chose to do the loan right after the creation of the account had the tendecy to be a bad client with an average of less than 300 days for groups "B" and "D". Good clients such as with status "A" and "C" had the custom to take more days between these events. For example, "A" and "C" took more than 350 by average for these events.
 Furthermore, i calculated the average for each status with the columns "payments" and "amount" as well to find if they had any pattern that could give me what i want. I found that good clients had the pattern to spend less with amounts and payments. Group "A" and "C" spent less than 4200 in average with payments and less than 170000 with amounts. Otherwise, groups "B" and "D" spent more than 5000 with payments and more for amounts in average than the status mentioned.
 Afterwards , i decided to do more two "INNER JOIN" function to get information about the tables "disposition" and "creditcard" because they had the columns "type" where i could know what type of creditcard and disposition the clients were settled. Doing the average separated by status i found that good clients had types of "Disponent" with more than 100 cases while the bad clients not. And about the creditcard, good clients had more accounts with the whole set of card such as "classic" , "gold" and "junior" while bad clients almost did not have accounts with credit cards.
 Also , i should mention that to calculate the average for specific cases, eliminate null values and extract only some data for me, know about subqueries or temporaries tables was another important knowledge to help me to get into the results because it allowed me to do the data cleaning correctly. So i used it to also implement a last "INNER JOIN" function to analyse the "Client" table because i knew that i could be handling with a lot of clients with just one account. If i would like to know specific things about clients i should go deep into information to find more patterns. I did the same approach about average because i just got more rows to analyze. Doing all the stuff again i concluded the same results but just with some differences with the values.
 # Conclusion and Values.
 Finally, to understand what were good and bad clients, the bank should see that good clients such as with status "A" and "C" had less payments and amounts available with a higher difference of days about the creation of the account and the date of loan while the others groups were the contrary.
How about the solid values that i got ? I started analysing 682 filled rows about the accounts where i had 203 cases to the status "A", 31 for "B", 403 for "C" and 45 for "D" so that was a dataset with more good clients than bad ones. The average of payments were: 4260 for "A", 5390 for "B", 3930 for "C" and 5280 for "D". The average of amounts were: 91640 for "A", 140720 for "B", 171410 for "C" and 250000 for "D". The part about the "creditcard" and "disposition" tables took 827 rows to analyze and the people with "disponent" type were 55 for "A" and 90 for "C". THe people with creditcard were 62 for "A", 105 for "C", 3 for "D" and 2 for "B". The last dataset was related to the table "client" where i analyzed 99240 rows , so much more than the other , but with same patterns about payments, gap days and amounts. "A" and "C" had the average of 4100 with payments, 386 with gap days and 133000 with amount. Otherwise , the groups "B" and "D" had the average of 57000 for payments , less than 360 for gap days and more than 232560 for amounts, complementing what i got formerly.
This project was so important for me to improve my skills with SQL and understand properly how the "JOIN" method works. Also to code in a different set because i was used to use python but with some practice during the third week of the bootcamp, i did not find so difficult to use SQL as my tool for analyzing and extracting data.
 
 
 
